services:
  uptime-kuma:
    image: louislam/uptime-kuma:1
    container_name: uptime-kuma
    restart: unless-stopped
    ports:
      - "127.0.0.1:3001:3001"
    volumes:
      - kuma:/app/data
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    restart: unless-stopped
    ports:
      - "127.0.0.1:3000:8080"
    volumes:
      - openwebui:/app/backend/data
      - "./data:/data"
    environment:
      - WEBUI_NAME=AI-Server
      - ENABLE_API_KEYS=True
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  telegram-interface:
    build:
      context: ./telegram-interface
    container_name: telegram-interface
    restart: unless-stopped
    env_file:
      - ./telegram-interface/.env
    depends_on:
      - openwebui
    volumes:
      - "./data:/data"
      - "/Users/bob/Library/Mobile Documents/com~apple~CloudDocs/Symphony SH/Bob_Library:/library"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://127.0.0.1:8081/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  remediator:
    build:
      context: ./remediator
    container_name: remediator
    restart: unless-stopped
    env_file:
      - ./remediator/.env
    ports:
      - "127.0.0.1:8090:8090"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - telegram-interface
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

volumes:
  kuma:
  openwebui:
